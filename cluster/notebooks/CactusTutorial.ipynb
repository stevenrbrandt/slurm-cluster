{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "\n",
    "Here you will find a step by step guide to downloading, configuring, and running the Einstein Toolkit. You may use this tutorial on a workstation or laptop, or on a supported cluster. Configuring the Einstein Toolkit on an unsupported cluster is beyond the scope of this tutorial. If you find something that does not work, please feel free to email users@einsteintoolkit.org.\n",
    "\n",
    "This tutorial is very basic and does not describe the internal workings of the Einstein Toolkit. For a more detailed introduction, please have a look a the [text](https://arxiv.org/abs/1305.5299) provided by Miguel Zilhão and Frank Löffler and the [one](https://arxiv.org/abs/2011.13314) by Nicholas Choustikov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Prerequisites</h2>\n",
    "When using the Einstein Toolkit on a laptop or workstation you will want a number of packages installed in order to download, compile and use the Einstein Toolkit components. If this is a machine which you control (i.e. you have root), you can install using one of the recipes that follow:\n",
    "\n",
    "On Mac, please first \n",
    "- Install [Xcode](https://itunes.apple.com/us/app/xcode/id497799835) from the Apple [App Store](https://itunes.apple.com/us/app/xcode/id497799835). In *addition* agree to Xcode license and install the Xcode Command Line Tools in Terminal \n",
    "```bash\n",
    "sudo xcodebuild -license\n",
    "sudo xcode-select --install\n",
    "```\n",
    "- when using MacPorts\n",
    "  - install MacPorts for your version of the Mac operating system, if you have not already installed it (https://www.macports.org/install.php). \n",
    "  - Next, please install the following packages, using the commands:\n",
    "```bash\n",
    "sudo port -N install pkgconfig gcc12 openmpi-gcc12 fftw-3 gsl zlib openssl subversion ld64 hdf5 +fortran +gfortran\n",
    "sudo port select mpi openmpi-gcc12-fortran\n",
    "sudo port select gcc mp-gcc12\n",
    "```\n",
    "- when using HomeBrew\n",
    "  - install HomeBrew for your version of the Mac operating system, if you have not already installed it (https://brew.sh/). \n",
    "  - make sure to add /opt/homebrew/bin to your PATH as instructed by the installation script. You may need to restart your terminal. \n",
    "  - Next, please install the following packages, using the commands:\n",
    "```bash\n",
    "brew install fftw gcc gsl hdf5 hwloc jpeg open-mpi openssl zlib pkg-config bash subversion\n",
    "brew link --force jpeg openssl zlib\n",
    "```\n",
    "\n",
    "On Debian/Ubuntu/Mint use this command (the strange syntax is to suport all three of them):\n",
    "```bash\n",
    "$(sudo -l sudo) su -c 'apt-get update'\n",
    "$(sudo -l sudo) su -c 'apt-get install -y subversion gcc git numactl libgsl-dev libpapi-dev python3 python-is-python3 python3-pip libhwloc-dev libudev-dev make libopenmpi-dev libhdf5-openmpi-dev libfftw3-dev libssl-dev liblapack-dev g++ curl gfortran patch pkg-config libhdf5-dev libjpeg-turbo?-dev'\n",
    "```\n",
    "\n",
    "On Fedora use this command:\n",
    "```bash\n",
    "sudo dnf install -y libjpeg-turbo-devel gcc git lapack-devel make subversion gcc-c++ which papi-devel perl python3 python3-pip hwloc-devel openmpi-devel hdf5-openmpi-devel openssl-devel libtool-ltdl-devel numactl-devel gcc-gfortran findutils hdf5-devel fftw-devel patch gsl-devel pkgconfig\n",
    "module load mpi/openmpi-x86_64\n",
    "```\n",
    "You will have to repeat the `module load` command once in each new shell each time you would like to compile or run the code. You may have to log out and back in for the module command to become visible.\n",
    "\n",
    "On Centos use this command:\n",
    "```bash\n",
    "su -c 'yum install -y epel-release'\n",
    "su -c 'yum install --enablerepo=crb -y libjpeg-turbo-devel gcc git lapack-devel make subversion gcc-c++ which python3 python3-pip papi-devel hwloc-devel openmpi-devel openssl-devel libtool-ltdl-devel numactl-devel gcc-gfortran fftw-devel patch gsl-devel perl'\n",
    "module load mpi/openmpi-x86_64\n",
    "```\n",
    "You will have to repeat the `module load` command once in each new shell each time you would like to compile or run the code. You may have to log out and back in for the module command to become visible.\n",
    "\n",
    "On OpenSuse use this command:\n",
    "```bash\n",
    "sudo zypper install -y curl gcc git lapack-devel make subversion gcc-c++ which python3 python3-pip papi-devel hwloc-devel openmpi-devel libopenssl-devel libnuma-devel gcc-fortran hdf5-devel libfftw3-3 patch gsl-devel pkg-config\n",
    "mpi-selector --set  $(mpi-selector --list | head -n1)\n",
    "```\n",
    "You will only have to execute the `mpi-selector` once, after that log out and back in to make the `mpirun` and `mpicc` commands visible without which Cactus will compile very slowly and fail to run.\n",
    "\n",
    "On Windows 10/11 please install the Ubuntu Linux subsystem, then follow the instructions for a Ubuntu system. [These](https://docs.microsoft.com/en-us/windows/wsl/install) are Microsoft's official instructions on how to do so, [Ubuntu](https://ubuntu.com/wsl#install-ubuntu-on-wsl) provides an alternative version. You may also want to install native ssh client like [Putty](https://www.chiark.greenend.org.uk/~sgtatham/putty/) and an X11 server like [VcXsrv](https://sourceforge.net/projects/vcxsrv/), [XMing](https://sourceforge.net/projects/xming/) or an all-in-one solution for X11 server and ssh client like [MobaXterm](https://mobaxterm.mobatek.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook setup\n",
    "This notebook is intended to be used online on the Einstein Toolkit tutorial server, offline as a read-only document, as a jupyter notebook that you can download and also in your own docker container using `nds-org/jupyter-et`. To make all of these work some setting need to be tweaked, which we do in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /usr/local/lib/et-setup.py\n",
    "# this allows you to use \"cd\" in cells to change directories instead of requiring \"%cd\"\n",
    "%automagic on\n",
    "# override IPython's default %%bash to not buffer all output\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from time import time, sleep\n",
    "import os\n",
    "home = os.path.expanduser(\"~/\")\n",
    "@register_cell_magic\n",
    "def bash(line, cell):\n",
    "    get_ipython().system(cell)\n",
    "@register_cell_magic\n",
    "def slurm(line, cell):\n",
    "    with open(f\"{home}/.slurm.sh\",\"w\") as fd:\n",
    "        fd.write(\"if [ ${SLURM_PROCID} != 0 ]; then exit 0; fi\\n\")\n",
    "        fd.write(cell)\n",
    "    get_ipython().system(f\"srun {line} bash {home}/.slurm.sh\")\n",
    "\n",
    "# this (non-default package) keeps the end of shell output in view\n",
    "try: import scrolldown\n",
    "except ModuleNotFoundError: pass\n",
    "\n",
    "# We are going to install kuibit, a Python package to post-process Cactus simulations.\n",
    "# We will install kuibit inside the Cactus directory. The main reason for this is to\n",
    "# have a make easier to uninstall kuibit (you can just remove the Cactus folder). \n",
    "import os, sys\n",
    "os.environ[\"PYTHONUSERBASE\"] = os.environ['HOME'] + \"/Cactus/python\"\n",
    "sys.path.insert(1, f\"{os.environ['PYTHONUSERBASE']}/lib/python{sys.version_info[0]}.{sys.version_info[1]}/site-packages\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> By default, the cells in this notebook are Python commands. However, cells that start with <code>%%bash</code> are executed in a bash shell. If you wish to run these commands outside the notebook and in a bash shell, cut and paste only the part after the initial <code>%%bash</code>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Help\n",
    "Gitter, email, bug trackers, etc can all be found here https://einsteintoolkit.org/support.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Download/Build Experience\n",
    "Downloading the source code from github in a classroom setting, where lots of users are doing the same thing at the same time, can create network problems, and compiling the complete ET from scratch can take up to half an hour.\n",
    "\n",
    "The next cell will create a complete pre-built ET checkout in your home directory, speeding up subsequent cells.  This step is optional, but should allow you to execute the notebook in less time.\n",
    "\n",
    "**Note:** This will only work in the docker image or on the tutorial server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ~/\n",
    "untar.py ~etuser/Cactus.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Download</h2>\n",
    "\n",
    "A script called GetComponents is used to fetch the components of the Einstein Toolkit. GetComponents serves as convenient wrapper around lower level tools like git and svn to download the codes that make up the Einstein toolkit from their individual repositories. You may download and make it executable as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -kLO https://raw.githubusercontent.com/gridaphobe/CRL/ET_2023_05/GetComponents\n",
    "chmod a+x GetComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GetComponents accepts a thorn list as an argument. To check out the needed components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./GetComponents https://bitbucket.org/einsteintoolkit/manifest/raw/ET_2023_05/einsteintoolkit.th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/Cactus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Configure and build</h2>\n",
    "\n",
    "The recommended way to compile the Einstein Toolkit is to use the Simulation Factory (\"SimFactory\").\n",
    "<h3>Configuring SimFactory for your machine</h3>\n",
    "\n",
    "The ET depends on various libraries, and needs to interact with machine-specific queueing systems and MPI implementations. As such, it needs to be configured for a given machine. For this, it uses SimFactory. Generally, configuring SimFactory means providing an optionlist, for specifying library locations and build options, a submit script for using the batch queueing system, and a runscript, for specifying how Cactus should be run, e.g. which mpirun command to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./simfactory/bin/sim setup-silent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step is complete you will find your machine's default setup under ./simfactory/mdb/machines/&lt;hostname &gt;.ini\n",
    "You can edit some of these settings freely, such as \"description\", \"basedir\" etc. Some entry edits could result in simulation start-up warnings and/or errors such as \"ppn\" (processor-per-node meaning number of cores on your machine), \"num-threads\" (number of threads per core) so such edits must be done with some care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building the Einstein Toolkit</h2>\n",
    "\n",
    "Assuming that SimFactory has been successfully set up on your machine, you should be able to build the Einstein Toolkit with the command below. The option \"-j2\" sets the make command that will be used by the script. The number used is the number of processes used when building. Even in parallel, this step may take a while, as it compiles all the thorns specified in thornlists/einsteintoolkit.th.\n",
    "\n",
    "Note: Using too many processes to compile on the test machine may result in compiler failures, if the system runs out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%slurm -n 2\n",
    "./simfactory/bin/sim build -j${SLURM_NPROCS} --thornlist thornlists/einsteintoolkit.th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running a simple example</h2>\n",
    "\n",
    "You can now run the Einstein Toolkit with a simple test parameter file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./simfactory/bin/sim create-run helloworld \\\n",
    "    --parfile arrangements/CactusExamples/HelloWorld/par/HelloWorld.par"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command will run the simulation naming it \"helloworld\" and display its log output to screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see <pre>INFO (HelloWorld): Hello World!</pre> anywhere in the above output, then congratulations, you have successfully downloaded, compiled and run the Einstein Toolkit! You may now want to try some of the other tutorials to explore some interesting physics examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Simple Wave Equation\n",
    "The wave equation can be described in Cartesian coordinates by the equations\n",
    "$u_{,t} = \\rho \\\\\n",
    "\\rho_{,t} = c^2 \\left(u_{,xx} + u_{,yy} \\right)$\n",
    "or, in spherical symmetry, it can be written as\n",
    "$u_{,t} = \\rho \\\\\n",
    "\\rho_{,t} = c^2 \\frac{1}{r^2}\\left( r^2 u_{,r}\\right)_{,r}$\n",
    "using polar coordinates. This code is implemented using Kranc (a Mathematica tool that generates Cactus code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile repos/mclachlan/ML_WaveToy_Test/test/gaussian-RK4.par\n",
    "# gaussian-RK4.par\n",
    "# Evolve the scalar wave equation with the RK4 integrator\n",
    "\n",
    "ActiveThorns = \"\n",
    "   Boundary\n",
    "   Carpet\n",
    "   CarpetIOASCII\n",
    "   CarpetIOBasic\n",
    "   CarpetIOScalar\n",
    "   CarpetLib\n",
    "   CarpetReduce\n",
    "   CartGrid3D\n",
    "   CoordBase\n",
    "   GenericFD\n",
    "   IOUtil\n",
    "   LoopControl\n",
    "   ML_WaveToy\n",
    "   MoL\n",
    "   SymBase\n",
    "   Time\n",
    "\"\n",
    "\n",
    "\n",
    "\n",
    "Carpet::domain_from_coordbase = yes\n",
    "CartGrid3D::type              = \"coordbase\"\n",
    "\n",
    "CoordBase::domainsize = \"minmax\"\n",
    "CoordBase::spacing    = \"numcells\"\n",
    "CoordBase::xmin       = -5.0\n",
    "CoordBase::ymin       = -5.0\n",
    "CoordBase::zmin       = -5.0\n",
    "CoordBase::xmax       = +5.0\n",
    "CoordBase::ymax       = +5.0\n",
    "CoordBase::zmax       = +5.0\n",
    "CoordBase::ncells_x   = 50\n",
    "CoordBase::ncells_y   = 50\n",
    "CoordBase::ncells_z   = 50\n",
    "\n",
    "CoordBase::boundary_size_x_lower = 2\n",
    "CoordBase::boundary_size_y_lower = 2\n",
    "CoordBase::boundary_size_z_lower = 2\n",
    "CoordBase::boundary_size_x_upper = 2\n",
    "CoordBase::boundary_size_y_upper = 2\n",
    "CoordBase::boundary_size_z_upper = 2\n",
    "Carpet::ghost_size               = 2\n",
    "\n",
    "\n",
    "\n",
    "Cactus::cctk_itlast = 100\n",
    "\n",
    "MoL::ODE_method             = \"RK4\"\n",
    "MoL::MoL_Intermediate_Steps = 4\n",
    "MoL::MoL_Num_Scratch_Levels = 1\n",
    "\n",
    "Time::dtfac = 0.5\n",
    "\n",
    "\n",
    "\n",
    "ML_WaveToy::initial_data = \"Gaussian\"\n",
    "ML_WaveToy::WT_u_bound   = \"newrad\"\n",
    "ML_WaveToy::WT_rho_bound = \"newrad\"\n",
    "\n",
    "\n",
    "\n",
    "IO::out_dir      = $parfile\n",
    "#IO::out_fileinfo = \"none\"\n",
    "\n",
    "IOBasic::outInfo_every = 1\n",
    "IOBasic::outInfo_vars  = \"ML_WaveToy::u\"\n",
    "\n",
    "IOScalar::outScalar_reductions = \"norm1 norm2 minimum maximum norm_inf\"\n",
    "IOScalar::outScalar_every      = 1\n",
    "IOScalar::outScalar_vars       = \"ML_WaveToy::WT_u\"\n",
    "\n",
    "IOASCII::out1D_every = 1\n",
    "IOASCII::out1D_vars  = \"ML_WaveToy::WT_u ML_WaveToy::WT_rho ML_WaveToy::WT_eps\"\n",
    "\n",
    "CarpetIOASCII::compact_format = yes\n",
    "CarpetIOASCII::output_ghost_points = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./simfactory/bin/sim create-submit wavetoy --cores 2 \\\n",
    "    --parfile repos/mclachlan/ML_WaveToy_Test/test/gaussian-RK4.par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "OUTPUT_DIR=$(./simfactory/bin/sim get-output-dir wavetoy)\n",
    "echo \"The output directory is:\"\n",
    "ls -d $OUTPUT_DIR/gaussian-RK4\n",
    "echo\n",
    "echo \"The contents of the output directory is:\"\n",
    "ls $OUTPUT_DIR/gaussian-RK4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the output\n",
    "The output for this wavetoy consists of simple ascii files. The rho function (which maps to either u or v in the equations above), is shown in the next cell. The \"d\" is for diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -20 $HOME/simulations/wavetoy/output-0000/gaussian-RK4/u.x.asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using numpy\n",
    "import os\n",
    "import numpy as np\n",
    "home = os.environ[\"HOME\"]\n",
    "data = np.genfromtxt(os.path.join(home,\"simulations\",\"wavetoy\",\"output-0000\",\"gaussian-RK4\",\"u.x.asc\"))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the timesteps from the output data\n",
    "time_steps = np.unique(data[:,0])\n",
    "print(time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 10 timesteps\n",
    "import matplotlib.pyplot as plt\n",
    "x = data[data[:,0] == time_steps[0]][:,5]\n",
    "for time_step in time_steps[:10]:\n",
    "    step_data = data[data[:,0] == time_step][:,-1]\n",
    "    plt.plot(x,step_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a movie using all the timesteps\n",
    "import matplotlib.pyplot as plt\n",
    "frameno = 0\n",
    "for time_step in time_steps:\n",
    "    plt.clf()\n",
    "    step_data = data[data[:,0] == time_step][:,-1]\n",
    "    plt.ylim([-1,1])\n",
    "    plt.plot(step_data)\n",
    "    frameno += 1\n",
    "    plt.savefig(\"plot%03d.png\" % frameno)\n",
    "    plt.close()\n",
    "\n",
    "from subprocess import call\n",
    "call([\"ffmpeg\", \"-i\", \"plot%03d.png\", \"-i\", \"plot001.png\",\n",
    "      \"-filter_complex\", \"[1:v] palettegen [p];[0:v][p] paletteuse\",\n",
    "      \"-y\", \"output.gif\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the movie\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(\"output.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing submitted simulations\n",
    "\n",
    "Since the `submit` command was used to start the  simulation, it is running in the background and you have to use simfactory commands to interact with it. The next cell shows how to list simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember** that you have to interrupt the kernel to stop `show-output` and be able to execute the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./simfactory/bin/sim list-simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simfactory offers a `stop` command to abort a running simulation. The next cell has the command intentionally commented out to prevent accidental stopping of your very first simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#./simfactory/bin/sim stop wavetoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after this the simulation changes to the \"FINISHED\" state indicating it is no longer running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulations that are no longer needed are removed using the `purge` command. The next cell has the command intentionally commented out to prevent accidental removing of your very first simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#./simfactory/bin/sim purge wavetoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "./simfactory/bin/sim show-output wavetoy --follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
